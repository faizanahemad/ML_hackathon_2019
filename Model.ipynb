{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T10:56:06.982560Z",
     "start_time": "2019-06-12T10:56:06.943268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np_utils\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, DepthwiseConv2D, Conv2D, SeparableConv2D, MaxPooling1D\n",
    "from keras.layers import Input, concatenate\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Nadam, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from keras_contrib.callbacks import CyclicLR\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from data_science_utils.vision.keras import *\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import missingno as msno\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "from data_science_utils import dataframe as df_utils\n",
    "from data_science_utils import models as model_utils\n",
    "from data_science_utils import plots as plot_utils\n",
    "from data_science_utils.dataframe import column as column_utils\n",
    "from data_science_utils import misc as misc\n",
    "from data_science_utils import preprocessing as pp_utils\n",
    "from data_science_utils import nlp as nlp_utils\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from data_science_utils.dataframe import get_specific_cols\n",
    "\n",
    "import more_itertools\n",
    "from more_itertools import flatten\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib' from '/home/ec2-user/SageMaker/ML_hackathon_2019/lib.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "from importlib import reload\n",
    "import lib\n",
    "reload(lib)\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:42:02.848654Z",
     "start_time": "2019-06-12T09:41:52.143642Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"price_prediction/train.csv\")\n",
    "df_test = pd.read_csv(\"price_prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(ast.literal_eval)\n",
    "df_train['text_encoded'] = df_train['text_encoded'].apply(ast.literal_eval)\n",
    "df_train['char_encoded'] = df_train['char_encoded'].apply(ast.literal_eval)\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(ast.literal_eval)\n",
    "df_test['text_encoded'] = df_test['text_encoded'].apply(ast.literal_eval)\n",
    "df_test['char_encoded'] = df_test['char_encoded'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T10:40:19.816205Z",
     "start_time": "2019-06-12T10:39:01.196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GL</th>\n",
       "      <th>text</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>char</th>\n",
       "      <th>char_encoded</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489960</td>\n",
       "      <td>gl_jewelry</td>\n",
       "      <td>['livsmart', 'resin', 'jewellery', 'display', ...</td>\n",
       "      <td>[28683, 1558, 273, 310, 196, 8, 4, 31, 453, 33...</td>\n",
       "      <td>Livsmart Resin Jewellery Display Stand, 17x11c...</td>\n",
       "      <td>[38, 8, 28, 10, 19, 4, 7, 6, 2, 45, 3, 10, 8, ...</td>\n",
       "      <td>507.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633493</td>\n",
       "      <td>gl_digital_ebook_purchase</td>\n",
       "      <td>['quantum', 'creation', 'supernatural', 'lurk'...</td>\n",
       "      <td>[7567, 879, 12991, 1, 3900, 207, 267]</td>\n",
       "      <td>Quantum Creation: Does the Supernatural Lurk i...</td>\n",
       "      <td>[78, 15, 4, 9, 6, 15, 19, 2, 23, 7, 3, 4, 6, 8...</td>\n",
       "      <td>479.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1474591</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['izod', 'men', 'casual', 'shirt', '_NUM30_', ...</td>\n",
       "      <td>[5244, 24, 35, 32, 127, 26671, 64, 5368, 9, 90...</td>\n",
       "      <td>IZOD Men's Casual Shirt (8907163477392_ZKSH019...</td>\n",
       "      <td>[41, 81, 46, 39, 2, 29, 3, 9, 63, 10, 2, 23, 4...</td>\n",
       "      <td>829.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>830218</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['dishaa', 'woman', 'rayon', 'line', 'kurta', ...</td>\n",
       "      <td>[45999, 21, 572, 192, 222, 31, 133, 2162, 369,...</td>\n",
       "      <td>Dishaa Women's Rayon A-Line Kurta (Black, X-La...</td>\n",
       "      <td>[39, 8, 10, 13, 4, 4, 2, 42, 5, 19, 3, 9, 63, ...</td>\n",
       "      <td>648.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201144</td>\n",
       "      <td>gl_digital_ebook_purchase</td>\n",
       "      <td>['return', 'raven', 'ulfrik', 'ormsson', 'saga...</td>\n",
       "      <td>[854, 13891, 1, 1, 7870, 597, 2, 267]</td>\n",
       "      <td>Return of the Ravens (Ulfrik Ormsson's Saga Bo...</td>\n",
       "      <td>[45, 3, 6, 15, 7, 9, 2, 5, 21, 2, 6, 13, 3, 2,...</td>\n",
       "      <td>332.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                         GL  \\\n",
       "0  1489960                 gl_jewelry   \n",
       "1   633493  gl_digital_ebook_purchase   \n",
       "2  1474591                 gl_apparel   \n",
       "3   830218                 gl_apparel   \n",
       "4   201144  gl_digital_ebook_purchase   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['livsmart', 'resin', 'jewellery', 'display', ...   \n",
       "1  ['quantum', 'creation', 'supernatural', 'lurk'...   \n",
       "2  ['izod', 'men', 'casual', 'shirt', '_NUM30_', ...   \n",
       "3  ['dishaa', 'woman', 'rayon', 'line', 'kurta', ...   \n",
       "4  ['return', 'raven', 'ulfrik', 'ormsson', 'saga...   \n",
       "\n",
       "                                        text_encoded  \\\n",
       "0  [28683, 1558, 273, 310, 196, 8, 4, 31, 453, 33...   \n",
       "1              [7567, 879, 12991, 1, 3900, 207, 267]   \n",
       "2  [5244, 24, 35, 32, 127, 26671, 64, 5368, 9, 90...   \n",
       "3  [45999, 21, 572, 192, 222, 31, 133, 2162, 369,...   \n",
       "4              [854, 13891, 1, 1, 7870, 597, 2, 267]   \n",
       "\n",
       "                                                char  \\\n",
       "0  Livsmart Resin Jewellery Display Stand, 17x11c...   \n",
       "1  Quantum Creation: Does the Supernatural Lurk i...   \n",
       "2  IZOD Men's Casual Shirt (8907163477392_ZKSH019...   \n",
       "3  Dishaa Women's Rayon A-Line Kurta (Black, X-La...   \n",
       "4  Return of the Ravens (Ulfrik Ormsson's Saga Bo...   \n",
       "\n",
       "                                        char_encoded   PRICE  \n",
       "0  [38, 8, 28, 10, 19, 4, 7, 6, 2, 45, 3, 10, 8, ...  507.62  \n",
       "1  [78, 15, 4, 9, 6, 15, 19, 2, 23, 7, 3, 4, 6, 8...  479.90  \n",
       "2  [41, 81, 46, 39, 2, 29, 3, 9, 63, 10, 2, 23, 4...  829.28  \n",
       "3  [39, 8, 10, 13, 4, 4, 2, 42, 5, 19, 3, 9, 63, ...  648.31  \n",
       "4  [45, 3, 6, 15, 7, 9, 2, 5, 21, 2, 6, 13, 3, 2,...  332.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GL</th>\n",
       "      <th>text</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>char</th>\n",
       "      <th>char_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585751</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['folklore', 'woman', 'straight', 'kurta', 'fo...</td>\n",
       "      <td>[10977, 21, 289, 222, 18034, 76, 2997, 1221, 6...</td>\n",
       "      <td>Folklore Women's Straight Kurta (FOKU001013_RE...</td>\n",
       "      <td>[40, 5, 11, 26, 11, 5, 7, 3, 2, 42, 5, 19, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530678</td>\n",
       "      <td>gl_toy</td>\n",
       "      <td>['rock', 'party', 'elephant', 'piggy', 'coin',...</td>\n",
       "      <td>[1699, 128, 2210, 5256, 1189, 1552, 170, 312]</td>\n",
       "      <td>Rock The Party Elephant Piggy Coin Bank (Pink)...</td>\n",
       "      <td>[45, 5, 12, 26, 2, 30, 13, 3, 2, 27, 4, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324955</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['cherokee', 'unlimited', 'girl', 'shirt', '_N...</td>\n",
       "      <td>[1743, 1043, 82, 32, 1316, 1837, 3727, 4, 4, 1...</td>\n",
       "      <td>Cherokee by Unlimited Girls' T-Shirt (26362639...</td>\n",
       "      <td>[23, 13, 3, 7, 5, 26, 3, 3, 2, 24, 20, 2, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822454</td>\n",
       "      <td>gl_biss</td>\n",
       "      <td>['packingsupply', 'premium', 'tamper', 'proof'...</td>\n",
       "      <td>[1, 54, 3065, 228, 6192, 71, 4754, 19, 4, 4, 7...</td>\n",
       "      <td>Packingsupply Premium Tamper Proof Courier Bag...</td>\n",
       "      <td>[27, 4, 12, 26, 8, 9, 16, 10, 15, 18, 18, 11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604015</td>\n",
       "      <td>gl_shoes</td>\n",
       "      <td>['contablue', 'funky', 'loafer', '_NUM3_', 'bl...</td>\n",
       "      <td>[15592, 2110, 734, 4, 31, 7, 320, 118, 35, 235...</td>\n",
       "      <td>CONTABLUE Funky Loafers (8 UK, Black)[Material...</td>\n",
       "      <td>[23, 46, 49, 30, 34, 32, 38, 58, 43, 2, 40, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID          GL                                               text  \\\n",
       "0  1585751  gl_apparel  ['folklore', 'woman', 'straight', 'kurta', 'fo...   \n",
       "1  1530678      gl_toy  ['rock', 'party', 'elephant', 'piggy', 'coin',...   \n",
       "2  1324955  gl_apparel  ['cherokee', 'unlimited', 'girl', 'shirt', '_N...   \n",
       "3   822454     gl_biss  ['packingsupply', 'premium', 'tamper', 'proof'...   \n",
       "4  1604015    gl_shoes  ['contablue', 'funky', 'loafer', '_NUM3_', 'bl...   \n",
       "\n",
       "                                        text_encoded  \\\n",
       "0  [10977, 21, 289, 222, 18034, 76, 2997, 1221, 6...   \n",
       "1      [1699, 128, 2210, 5256, 1189, 1552, 170, 312]   \n",
       "2  [1743, 1043, 82, 32, 1316, 1837, 3727, 4, 4, 1...   \n",
       "3  [1, 54, 3065, 228, 6192, 71, 4754, 19, 4, 4, 7...   \n",
       "4  [15592, 2110, 734, 4, 31, 7, 320, 118, 35, 235...   \n",
       "\n",
       "                                                char  \\\n",
       "0  Folklore Women's Straight Kurta (FOKU001013_RE...   \n",
       "1  Rock The Party Elephant Piggy Coin Bank (Pink)...   \n",
       "2  Cherokee by Unlimited Girls' T-Shirt (26362639...   \n",
       "3  Packingsupply Premium Tamper Proof Courier Bag...   \n",
       "4  CONTABLUE Funky Loafers (8 UK, Black)[Material...   \n",
       "\n",
       "                                        char_encoded  \n",
       "0  [40, 5, 11, 26, 11, 5, 7, 3, 2, 42, 5, 19, 3, ...  \n",
       "1  [45, 5, 12, 26, 2, 30, 13, 3, 2, 27, 4, 7, 6, ...  \n",
       "2  [23, 13, 3, 7, 5, 26, 3, 3, 2, 24, 20, 2, 58, ...  \n",
       "3  [27, 4, 12, 26, 8, 9, 16, 10, 15, 18, 18, 11, ...  \n",
       "4  [23, 46, 49, 30, 34, 32, 38, 58, 43, 2, 40, 15...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "- GL Mean\n",
    "- GL Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:05:25.984142Z",
     "start_time": "2019-06-12T09:05:25.507678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585751</td>\n",
       "      <td>772.612384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530678</td>\n",
       "      <td>1290.724354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324955</td>\n",
       "      <td>772.612384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822454</td>\n",
       "      <td>2321.772340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604015</td>\n",
       "      <td>1115.235239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        PRICE\n",
       "0  1585751   772.612384\n",
       "1  1530678  1290.724354\n",
       "2  1324955   772.612384\n",
       "3   822454  2321.772340\n",
       "4  1604015  1115.235239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gl_means = df_train.groupby([\"GL\"])[['PRICE']].mean().reset_index()\n",
    "\n",
    "df_results = df_test.merge(df_gl_means, on=[\"GL\"],how=\"left\")\n",
    "df_results = df_results[[\"ID\",\"PRICE\"]]\n",
    "df_results[\"PRICE\"] = df_results[\"PRICE\"].fillna(df_results[\"PRICE\"].mean())\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:05:50.559363Z",
     "start_time": "2019-06-12T09:05:49.247666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results.to_csv(\"baseline.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## For Word Embedding CNN\n",
    "- Making a text column\n",
    "    - append GL\n",
    "    - replace num\n",
    "    - replace measurement\n",
    "    \n",
    "- Hyper Params here:\n",
    "    - Stopwords\n",
    "    - word_length_filter\n",
    "    - lemmatize or not\n",
    "    - vocab_size in build_dict\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: Keras Imdb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159686/1159686 [==============================] - 341s 294us/step - loss: 4033933786.3938 - mean_absolute_error: 894.5309 - val_loss: 16347761.4813 - val_mean_absolute_error: 716.5794\n",
      "Epoch 2/5\n",
      "1159686/1159686 [==============================] - 340s 293us/step - loss: 4032204864.3942 - mean_absolute_error: 822.3543 - val_loss: 15832785.5048 - val_mean_absolute_error: 704.4332\n",
      "Epoch 3/5\n",
      "1159686/1159686 [==============================] - 339s 292us/step - loss: 4031421547.0617 - mean_absolute_error: 794.2296 - val_loss: 15649164.7560 - val_mean_absolute_error: 698.5270\n",
      "Epoch 4/5\n",
      "1159686/1159686 [==============================] - 341s 294us/step - loss: 4030308633.8232 - mean_absolute_error: 781.7042 - val_loss: 15564212.7209 - val_mean_absolute_error: 678.7286\n",
      "Epoch 5/5\n",
      "1159686/1159686 [==============================] - 342s 295us/step - loss: 4028990347.3919 - mean_absolute_error: 773.1664 - val_loss: 15462277.1944 - val_mean_absolute_error: 689.7498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc8e2027b8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "# set parameters:\n",
    "max_features = 50000\n",
    "maxlen = 100\n",
    "batch_size = 256\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "X,y = df_train['text_encoded'].values,df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "model.count_params()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['text_encoded'].values\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "df_results = df_test[['ID']]\n",
    "df_results['PRICE'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585751</td>\n",
       "      <td>402.462646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530678</td>\n",
       "      <td>708.144775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324955</td>\n",
       "      <td>199.348129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822454</td>\n",
       "      <td>2087.896729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604015</td>\n",
       "      <td>637.491211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        PRICE\n",
       "0  1585751   402.462646\n",
       "1  1530678   708.144775\n",
       "2  1324955   199.348129\n",
       "3   822454  2087.896729\n",
       "4  1604015   637.491211"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()\n",
    "df_results.to_csv(\"baseline-2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600751"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 50)           2500000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 250)           37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,600,751\n",
      "Trainable params: 2,600,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.count_params()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000\n",
    "maxlen = 100\n",
    "batch_size = 4096\n",
    "embedding_dims = 50\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "X,y = df_train['text_encoded'].values,df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "inputs = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=embedding_dims, input_dim=max_features, input_length=maxlen)(inputs)\n",
    "K.int_shape(x)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=5,padding='valid')\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=3,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=3,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=3,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "\n",
    "\n",
    "\n",
    "xp = pre_dense_layer(x)\n",
    "K.int_shape(x)\n",
    "print(K.int_shape(xp))\n",
    "x = Dense(128)(xp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "K.int_shape(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "print(model.count_params())\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ' 57, 17, 34, 10, 10, 5, 7, 6, 3, 14, 2, 23, 5, 11, 5, 7, 10, 17, 45, 5, 15, 9, 14, 2, 49, 3, 12, 26, 17, 23, 4, 7, 3, 2, 41, 9, 10, 6, 7, 15, 12, 6, 8, 5, 9, 10, 31, 2, 42, 4, 10, 13, 2, 14, 4, 7, 26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ab8b7dc0d484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ' 57, 17, 34, 10, 10, 5, 7, 6, 3, 14, 2, 23, 5, 11, 5, 7, 10, 17, 45, 5, 15, 9, 14, 2, 49, 3, 12, 26, 17, 23, 4, 7, 3, 2, 41, 9, 10, 6, 7, 15, 12, 6, 8, 5, 9, 10, 31, 2, 42, 4, 10, 13, 2, 14, 4, 7, 26"
     ]
    }
   ],
   "source": [
    "max_features = 128\n",
    "maxlen = 500\n",
    "batch_size = 4096\n",
    "embedding_dims = 50\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "X,y = df_train['char_encoded'].values,df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "inputs = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=embedding_dims, input_dim=max_features, input_length=maxlen)(inputs)\n",
    "K.int_shape(x)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=25,padding='valid')\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=15,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=15,padding='valid')\n",
    "x = transition_layer(x, n_kernels=128,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=15,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=15,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=15,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=15,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=15,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=15,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "\n",
    "\n",
    "xp = pre_dense_layer(x)\n",
    "K.int_shape(x)\n",
    "print(K.int_shape(xp))\n",
    "x = Dense(128)(xp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "K.int_shape(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "print(model.count_params())\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext Transforms start at: 2019-06-12 15:50:49.517983\n",
      "Number of Unique Test Tokens for Fasttext transform 332242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1c9e2b295040cc9cbe9f30c3c1deba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxlen = 100\n",
    "batch_size = 4096\n",
    "embedding_dims = 300\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "X,y = ptr.transform(df_train['text'].values),df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_44: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-761b207a5622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'main_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-6a8fb0263422>\u001b[0m in \u001b[0;36mconv_layer\u001b[0;34m(inputs, n_kernels, kernel_size, dropout, dilation_rate, padding)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 dilation_rate=dilation_rate)(inputs)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_44: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(None,embedding_dims), dtype='int32', name='main_input')\n",
    "\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=5,padding='valid')\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=3,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=3,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=3,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "\n",
    "\n",
    "xp = pre_dense_layer(x)\n",
    "x = Dense(128)(xp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "K.int_shape(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "print(model.count_params())\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "- gl min max clipping\n",
    "- max(0,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
