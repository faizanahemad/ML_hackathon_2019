{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T10:56:06.982560Z",
     "start_time": "2019-06-12T10:56:06.943268Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np_utils\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, DepthwiseConv2D, Conv2D, SeparableConv2D, MaxPooling1D\n",
    "from keras.layers import Input, concatenate\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Nadam, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from keras_contrib.callbacks import CyclicLR\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from data_science_utils.vision.keras import *\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import missingno as msno\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "from data_science_utils import dataframe as df_utils\n",
    "from data_science_utils import models as model_utils\n",
    "from data_science_utils import plots as plot_utils\n",
    "from data_science_utils.dataframe import column as column_utils\n",
    "from data_science_utils import misc as misc\n",
    "from data_science_utils import preprocessing as pp_utils\n",
    "from data_science_utils import nlp as nlp_utils\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from data_science_utils.dataframe import get_specific_cols\n",
    "\n",
    "import more_itertools\n",
    "from more_itertools import flatten\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib' from '/home/ec2-user/SageMaker/ML_hackathon_2019/lib.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "from importlib import reload\n",
    "import lib\n",
    "reload(lib)\n",
    "from lib import *\n",
    "\n",
    "from oclr import OneCycleLR, LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:42:02.848654Z",
     "start_time": "2019-06-12T09:41:52.143642Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"price_prediction/train.csv\")\n",
    "df_test = pd.read_csv(\"price_prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9160b7525314b08bc7320826983ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c54bfb31724669a205e6196b104b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b2025dac20405baa85083348a8941a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0231b20ef61e4e3694b1351019337158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7c846b73ef4696a5db953dfca4921c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737a1656e90e4c79a6540c48ea7524d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['text'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_train['text']))\n",
    "df_train['text_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_train['text_encoded']))\n",
    "df_train['char_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_train['char_encoded']))\n",
    "\n",
    "df_test['text'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_test['text']))\n",
    "df_test['text_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_test['text_encoded']))\n",
    "df_test['char_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_test['char_encoded']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T10:40:19.816205Z",
     "start_time": "2019-06-12T10:39:01.196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GL</th>\n",
       "      <th>text</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>char</th>\n",
       "      <th>char_encoded</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489960</td>\n",
       "      <td>gl_jewelry</td>\n",
       "      <td>['livsmart', 'resin', 'jewellery', 'display', ...</td>\n",
       "      <td>[28683, 1558, 273, 310, 196, 8, 4, 31, 453, 33...</td>\n",
       "      <td>Livsmart Resin Jewellery Display Stand, 17x11c...</td>\n",
       "      <td>[38, 8, 28, 10, 19, 4, 7, 6, 2, 45, 3, 10, 8, ...</td>\n",
       "      <td>507.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633493</td>\n",
       "      <td>gl_digital_ebook_purchase</td>\n",
       "      <td>['quantum', 'creation', 'supernatural', 'lurk'...</td>\n",
       "      <td>[7567, 879, 12991, 1, 3900, 207, 267]</td>\n",
       "      <td>Quantum Creation: Does the Supernatural Lurk i...</td>\n",
       "      <td>[78, 15, 4, 9, 6, 15, 19, 2, 23, 7, 3, 4, 6, 8...</td>\n",
       "      <td>479.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1474591</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['izod', 'men', 'casual', 'shirt', '_NUM30_', ...</td>\n",
       "      <td>[5244, 24, 35, 32, 127, 26671, 64, 5368, 9, 90...</td>\n",
       "      <td>IZOD Men's Casual Shirt (8907163477392_ZKSH019...</td>\n",
       "      <td>[41, 81, 46, 39, 2, 29, 3, 9, 63, 10, 2, 23, 4...</td>\n",
       "      <td>829.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>830218</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['dishaa', 'woman', 'rayon', 'line', 'kurta', ...</td>\n",
       "      <td>[45999, 21, 572, 192, 222, 31, 133, 2162, 369,...</td>\n",
       "      <td>Dishaa Women's Rayon A-Line Kurta (Black, X-La...</td>\n",
       "      <td>[39, 8, 10, 13, 4, 4, 2, 42, 5, 19, 3, 9, 63, ...</td>\n",
       "      <td>648.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201144</td>\n",
       "      <td>gl_digital_ebook_purchase</td>\n",
       "      <td>['return', 'raven', 'ulfrik', 'ormsson', 'saga...</td>\n",
       "      <td>[854, 13891, 1, 1, 7870, 597, 2, 267]</td>\n",
       "      <td>Return of the Ravens (Ulfrik Ormsson's Saga Bo...</td>\n",
       "      <td>[45, 3, 6, 15, 7, 9, 2, 5, 21, 2, 6, 13, 3, 2,...</td>\n",
       "      <td>332.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                         GL  \\\n",
       "0  1489960                 gl_jewelry   \n",
       "1   633493  gl_digital_ebook_purchase   \n",
       "2  1474591                 gl_apparel   \n",
       "3   830218                 gl_apparel   \n",
       "4   201144  gl_digital_ebook_purchase   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['livsmart', 'resin', 'jewellery', 'display', ...   \n",
       "1  ['quantum', 'creation', 'supernatural', 'lurk'...   \n",
       "2  ['izod', 'men', 'casual', 'shirt', '_NUM30_', ...   \n",
       "3  ['dishaa', 'woman', 'rayon', 'line', 'kurta', ...   \n",
       "4  ['return', 'raven', 'ulfrik', 'ormsson', 'saga...   \n",
       "\n",
       "                                        text_encoded  \\\n",
       "0  [28683, 1558, 273, 310, 196, 8, 4, 31, 453, 33...   \n",
       "1              [7567, 879, 12991, 1, 3900, 207, 267]   \n",
       "2  [5244, 24, 35, 32, 127, 26671, 64, 5368, 9, 90...   \n",
       "3  [45999, 21, 572, 192, 222, 31, 133, 2162, 369,...   \n",
       "4              [854, 13891, 1, 1, 7870, 597, 2, 267]   \n",
       "\n",
       "                                                char  \\\n",
       "0  Livsmart Resin Jewellery Display Stand, 17x11c...   \n",
       "1  Quantum Creation: Does the Supernatural Lurk i...   \n",
       "2  IZOD Men's Casual Shirt (8907163477392_ZKSH019...   \n",
       "3  Dishaa Women's Rayon A-Line Kurta (Black, X-La...   \n",
       "4  Return of the Ravens (Ulfrik Ormsson's Saga Bo...   \n",
       "\n",
       "                                        char_encoded   PRICE  \n",
       "0  [38, 8, 28, 10, 19, 4, 7, 6, 2, 45, 3, 10, 8, ...  507.62  \n",
       "1  [78, 15, 4, 9, 6, 15, 19, 2, 23, 7, 3, 4, 6, 8...  479.90  \n",
       "2  [41, 81, 46, 39, 2, 29, 3, 9, 63, 10, 2, 23, 4...  829.28  \n",
       "3  [39, 8, 10, 13, 4, 4, 2, 42, 5, 19, 3, 9, 63, ...  648.31  \n",
       "4  [45, 3, 6, 15, 7, 9, 2, 5, 21, 2, 6, 13, 3, 2,...  332.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GL</th>\n",
       "      <th>text</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>char</th>\n",
       "      <th>char_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585751</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['folklore', 'woman', 'straight', 'kurta', 'fo...</td>\n",
       "      <td>[10977, 21, 289, 222, 18034, 76, 2997, 1221, 6...</td>\n",
       "      <td>Folklore Women's Straight Kurta (FOKU001013_RE...</td>\n",
       "      <td>[40, 5, 11, 26, 11, 5, 7, 3, 2, 42, 5, 19, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530678</td>\n",
       "      <td>gl_toy</td>\n",
       "      <td>['rock', 'party', 'elephant', 'piggy', 'coin',...</td>\n",
       "      <td>[1699, 128, 2210, 5256, 1189, 1552, 170, 312]</td>\n",
       "      <td>Rock The Party Elephant Piggy Coin Bank (Pink)...</td>\n",
       "      <td>[45, 5, 12, 26, 2, 30, 13, 3, 2, 27, 4, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324955</td>\n",
       "      <td>gl_apparel</td>\n",
       "      <td>['cherokee', 'unlimited', 'girl', 'shirt', '_N...</td>\n",
       "      <td>[1743, 1043, 82, 32, 1316, 1837, 3727, 4, 4, 1...</td>\n",
       "      <td>Cherokee by Unlimited Girls' T-Shirt (26362639...</td>\n",
       "      <td>[23, 13, 3, 7, 5, 26, 3, 3, 2, 24, 20, 2, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822454</td>\n",
       "      <td>gl_biss</td>\n",
       "      <td>['packingsupply', 'premium', 'tamper', 'proof'...</td>\n",
       "      <td>[1, 54, 3065, 228, 6192, 71, 4754, 19, 4, 4, 7...</td>\n",
       "      <td>Packingsupply Premium Tamper Proof Courier Bag...</td>\n",
       "      <td>[27, 4, 12, 26, 8, 9, 16, 10, 15, 18, 18, 11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604015</td>\n",
       "      <td>gl_shoes</td>\n",
       "      <td>['contablue', 'funky', 'loafer', '_NUM3_', 'bl...</td>\n",
       "      <td>[15592, 2110, 734, 4, 31, 7, 320, 118, 35, 235...</td>\n",
       "      <td>CONTABLUE Funky Loafers (8 UK, Black)[Material...</td>\n",
       "      <td>[23, 46, 49, 30, 34, 32, 38, 58, 43, 2, 40, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID          GL                                               text  \\\n",
       "0  1585751  gl_apparel  ['folklore', 'woman', 'straight', 'kurta', 'fo...   \n",
       "1  1530678      gl_toy  ['rock', 'party', 'elephant', 'piggy', 'coin',...   \n",
       "2  1324955  gl_apparel  ['cherokee', 'unlimited', 'girl', 'shirt', '_N...   \n",
       "3   822454     gl_biss  ['packingsupply', 'premium', 'tamper', 'proof'...   \n",
       "4  1604015    gl_shoes  ['contablue', 'funky', 'loafer', '_NUM3_', 'bl...   \n",
       "\n",
       "                                        text_encoded  \\\n",
       "0  [10977, 21, 289, 222, 18034, 76, 2997, 1221, 6...   \n",
       "1      [1699, 128, 2210, 5256, 1189, 1552, 170, 312]   \n",
       "2  [1743, 1043, 82, 32, 1316, 1837, 3727, 4, 4, 1...   \n",
       "3  [1, 54, 3065, 228, 6192, 71, 4754, 19, 4, 4, 7...   \n",
       "4  [15592, 2110, 734, 4, 31, 7, 320, 118, 35, 235...   \n",
       "\n",
       "                                                char  \\\n",
       "0  Folklore Women's Straight Kurta (FOKU001013_RE...   \n",
       "1  Rock The Party Elephant Piggy Coin Bank (Pink)...   \n",
       "2  Cherokee by Unlimited Girls' T-Shirt (26362639...   \n",
       "3  Packingsupply Premium Tamper Proof Courier Bag...   \n",
       "4  CONTABLUE Funky Loafers (8 UK, Black)[Material...   \n",
       "\n",
       "                                        char_encoded  \n",
       "0  [40, 5, 11, 26, 11, 5, 7, 3, 2, 42, 5, 19, 3, ...  \n",
       "1  [45, 5, 12, 26, 2, 30, 13, 3, 2, 27, 4, 7, 6, ...  \n",
       "2  [23, 13, 3, 7, 5, 26, 3, 3, 2, 24, 20, 2, 58, ...  \n",
       "3  [27, 4, 12, 26, 8, 9, 16, 10, 15, 18, 18, 11, ...  \n",
       "4  [23, 46, 49, 30, 34, 32, 38, 58, 43, 2, 40, 15...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GL encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Categorical fit start at: 2019-06-13 04:25:47.154903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input to Neural Network: (61, 61), Output shape: (61, 69)\n",
      "Train on 37 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 0.2416 - val_loss: 0.2380\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 0s 56us/step - loss: 0.2368 - val_loss: 0.2329\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 0s 46us/step - loss: 0.2296 - val_loss: 0.2255\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.2193 - val_loss: 0.2155\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 0s 46us/step - loss: 0.2055 - val_loss: 0.2026\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 0s 45us/step - loss: 0.1881 - val_loss: 0.1867\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 0s 46us/step - loss: 0.1672 - val_loss: 0.1682\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 0s 47us/step - loss: 0.1437 - val_loss: 0.1476\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.1191 - val_loss: 0.1258\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 0s 45us/step - loss: 0.0950 - val_loss: 0.1041\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 0s 53us/step - loss: 0.0734 - val_loss: 0.0838\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.0555 - val_loss: 0.0661\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.0418 - val_loss: 0.0517\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 0s 45us/step - loss: 0.0322 - val_loss: 0.0407\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 0s 53us/step - loss: 0.0260 - val_loss: 0.0328\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.0222 - val_loss: 0.0273\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 0s 49us/step - loss: 0.0201 - val_loss: 0.0237\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 0s 45us/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 0s 47us/step - loss: 0.0184 - val_loss: 0.0189\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 0s 43us/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 0s 52us/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 0s 47us/step - loss: 0.0184 - val_loss: 0.0176\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 0s 51us/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 0s 57us/step - loss: 0.0185 - val_loss: 0.0173\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.0185 - val_loss: 0.0173\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 0s 47us/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 0s 49us/step - loss: 0.0185 - val_loss: 0.0173\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.0186 - val_loss: 0.0173\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 0s 43us/step - loss: 0.0186 - val_loss: 0.0173\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 0s 46us/step - loss: 0.0186 - val_loss: 0.0173\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 0s 58us/step - loss: 0.0186 - val_loss: 0.0173\n",
      "Train on 24 samples, validate on 37 samples\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 89us/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 66us/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0171 - val_loss: 0.0187\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 69us/step - loss: 0.0171 - val_loss: 0.0188\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0170 - val_loss: 0.0190\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 70us/step - loss: 0.0170 - val_loss: 0.0191\n",
      "Neural Categorical fit done at: 2019-06-13 04:26:08.604625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<data_science_utils.preprocessing.NeuralCategoricalFeatureTransformer at 0x7f02a042fb38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_science_utils.preprocessing import NeuralCategoricalFeatureTransformer\n",
    "\n",
    "ct_nn = NeuralCategoricalFeatureTransformer(cols=[\"GL\"],prefix=\"gl_encoded_\",\n",
    "                                            target_columns=[\"PRICE\"],verbose=1,n_components=16,n_iter=200,)\n",
    "\n",
    "ct_nn.fit(df_train)\n",
    "\n",
    "ct_nn.skip_fit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ct_nn.transform(df_train)\n",
    "df_test = ct_nn.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_cols = get_specific_cols(df_train,prefix='gl_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "- GL Mean\n",
    "- GL Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:05:25.984142Z",
     "start_time": "2019-06-12T09:05:25.507678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585751</td>\n",
       "      <td>772.612384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530678</td>\n",
       "      <td>1290.724354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324955</td>\n",
       "      <td>772.612384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822454</td>\n",
       "      <td>2321.772340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604015</td>\n",
       "      <td>1115.235239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        PRICE\n",
       "0  1585751   772.612384\n",
       "1  1530678  1290.724354\n",
       "2  1324955   772.612384\n",
       "3   822454  2321.772340\n",
       "4  1604015  1115.235239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gl_means = df_train.groupby([\"GL\"])[['PRICE']].mean().reset_index()\n",
    "\n",
    "df_results = df_test.merge(df_gl_means, on=[\"GL\"],how=\"left\")\n",
    "df_results = df_results[[\"ID\",\"PRICE\"]]\n",
    "df_results[\"PRICE\"] = df_results[\"PRICE\"].fillna(df_results[\"PRICE\"].mean())\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:05:50.559363Z",
     "start_time": "2019-06-12T09:05:49.247666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results.to_csv(\"baseline.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## For Word Embedding CNN\n",
    "- Making a text column\n",
    "    - append GL\n",
    "    - replace num\n",
    "    - replace measurement\n",
    "    \n",
    "- Hyper Params here:\n",
    "    - Stopwords\n",
    "    - word_length_filter\n",
    "    - lemmatize or not\n",
    "    - vocab_size in build_dict\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: Keras Imdb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159686/1159686 [==============================] - 341s 294us/step - loss: 4033933786.3938 - mean_absolute_error: 894.5309 - val_loss: 16347761.4813 - val_mean_absolute_error: 716.5794\n",
      "Epoch 2/5\n",
      "1159686/1159686 [==============================] - 340s 293us/step - loss: 4032204864.3942 - mean_absolute_error: 822.3543 - val_loss: 15832785.5048 - val_mean_absolute_error: 704.4332\n",
      "Epoch 3/5\n",
      "1159686/1159686 [==============================] - 339s 292us/step - loss: 4031421547.0617 - mean_absolute_error: 794.2296 - val_loss: 15649164.7560 - val_mean_absolute_error: 698.5270\n",
      "Epoch 4/5\n",
      "1159686/1159686 [==============================] - 341s 294us/step - loss: 4030308633.8232 - mean_absolute_error: 781.7042 - val_loss: 15564212.7209 - val_mean_absolute_error: 678.7286\n",
      "Epoch 5/5\n",
      "1159686/1159686 [==============================] - 342s 295us/step - loss: 4028990347.3919 - mean_absolute_error: 773.1664 - val_loss: 15462277.1944 - val_mean_absolute_error: 689.7498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc8e2027b8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "# set parameters:\n",
    "max_features = 50000\n",
    "maxlen = 100\n",
    "batch_size = 256\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "X,y = df_train['text_encoded'].values,df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "model.count_params()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "# set parameters:\n",
    "max_features = 50000\n",
    "maxlen = 100\n",
    "batch_size = 256\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "X,X_gl,y = df_train['text_encoded'].values,df_train[gl_cols],df_train['PRICE'].values\n",
    "x_train, x_test,x_gl_train,x_gl_test, y_train, y_test = train_test_split(X,X_gl, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "x = Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen)(main_input)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "x = Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1)(x)\n",
    "# we use max pooling:\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "auxiliary_input =  Input(shape=(len(gl_cols),), dtype='float32', name='aux_input')\n",
    "x = concatenate([x,auxiliary_input])\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = Dense(hidden_dims)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x =Activation('relu')(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "main_output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "model.count_params()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['text_encoded'].values\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "df_results = df_test[['ID']]\n",
    "df_results['PRICE'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585751</td>\n",
       "      <td>402.462646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530678</td>\n",
       "      <td>708.144775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324955</td>\n",
       "      <td>199.348129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822454</td>\n",
       "      <td>2087.896729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604015</td>\n",
       "      <td>637.491211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        PRICE\n",
       "0  1585751   402.462646\n",
       "1  1530678   708.144775\n",
       "2  1324955   199.348129\n",
       "3   822454  2087.896729\n",
       "4  1604015   637.491211"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()\n",
    "df_results.to_csv(\"baseline-2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600751"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 50)           2500000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 250)           37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,600,751\n",
      "Trainable params: 2,600,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.count_params()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 23, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(None, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params =  2552801\n",
      "Train on 1159686 samples, validate on 289922 samples\n",
      "Epoch 1/5\n",
      "1159686/1159686 [==============================] - 349s 301us/step - loss: 4036298900.6407 - mean_absolute_error: 986.6706 - mean_squared_error: 4036298900.6407 - val_loss: 16932477.8903 - val_mean_absolute_error: 698.4354 - val_mean_squared_error: 16932477.8903\n",
      " - lr: 0.00897 \n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with mse available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 815104/1159686 [====================>.........] - ETA: 1:34 - loss: 5724208036.0540 - mean_absolute_error: 905.9615 - mean_squared_error: 5724208036.0540"
     ]
    }
   ],
   "source": [
    "max_features = 50000\n",
    "maxlen = 100\n",
    "batch_size = 4096\n",
    "embedding_dims = 50\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "X,y = df_train['text_encoded'].values,df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "inputs = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=embedding_dims, input_dim=max_features, input_length=maxlen)(inputs)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=5,padding='valid')\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=3,padding='valid')\n",
    "x = MaxPooling1D()(x)\n",
    "K.int_shape(x)\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "\n",
    "xp = pre_dense_layer(x)\n",
    "output = Dense(1)(xp)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model.hdf5\", monitor='mse', verbose=0, save_best_only=True, mode='max')\n",
    "lr_manager = OneCycleLR(samples=x_train.shape[0], epochs=2, batch_size=batch_size,\n",
    "                        steps=int(np.floor(x_train.shape[0]/batch_size)), max_lr=0.01,\n",
    "                        end_percentage=0.1, scale_percentage=None,\n",
    "                        maximum_momentum=None, minimum_momentum=None)\n",
    "\n",
    "callbacks_list = [lr_manager,checkpoint]\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "print(\"Params = \",model.count_params())\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,callbacks=callbacks_list,verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "model.load_weights(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 203, 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(None, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params =  67025\n",
      "Train on 1159686 samples, validate on 289922 samples\n",
      "Epoch 1/2\n",
      "1159686/1159686 [==============================] - 929s 801us/step - loss: 4035681405.2569 - mean_absolute_error: 1038.8304 - mean_squared_error: 4035681405.2569 - val_loss: 18686002.3946 - val_mean_absolute_error: 896.4453 - val_mean_squared_error: 18686002.3946\n",
      " - lr: 0.00899 \n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with mse available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 152576/1159686 [==>...........................] - ETA: 12:11 - loss: 43844717.4111 - mean_absolute_error: 1006.2062 - mean_squared_error: 43844717.4111"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e6f3a2eb951b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = 128\n",
    "maxlen = 500\n",
    "batch_size = 1024\n",
    "embedding_dims = 20\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "X,y = df_train['char_encoded'].values,df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "inputs = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=embedding_dims, input_dim=max_features, input_length=maxlen)(inputs)\n",
    "x = conv_layer(x,n_kernels=32,kernel_size=25,padding='valid')\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=15,padding='valid')\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=15,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "\n",
    "K.int_shape(x)\n",
    "xp = pre_dense_layer(x)\n",
    "K.int_shape(xp)\n",
    "x = Dense(16)(xp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model.hdf5\", monitor='mse', verbose=0, save_best_only=True, mode='max')\n",
    "lr_manager = OneCycleLR(samples=x_train.shape[0], epochs=2, batch_size=batch_size,\n",
    "                        steps=int(np.floor(x_train.shape[0]/batch_size)), max_lr=0.01,\n",
    "                        end_percentage=0.1, scale_percentage=None,\n",
    "                        maximum_momentum=None, minimum_momentum=None)\n",
    "\n",
    "callbacks_list = [lr_manager,checkpoint]\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "print(\"Params = \",model.count_params())\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,callbacks=callbacks_list,verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "model.load_weights(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 500, 50)      6400        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 476, 32)      40032       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 476, 32)      128         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 476, 32)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 476, 32)      0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 462, 64)      30784       dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 462, 64)      256         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 462, 64)      0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 462, 64)      0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 231, 64)      0           dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 231, 32)      2080        max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 231, 32)      128         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 231, 32)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 231, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 217, 32)      15392       dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 217, 32)      128         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 217, 32)      0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 217, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 203, 64)      30784       dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 203, 64)      256         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 203, 64)      0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 203, 64)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 101, 64)      0           dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 101, 32)      2080        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 101, 32)      128         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 101, 32)      0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 101, 32)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 92, 32)       10272       dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 92, 32)       128         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 92, 32)       0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 92, 32)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 83, 64)       20544       dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 83, 64)       256         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 83, 64)       0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 83, 64)       0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 41, 64)       0           dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 41, 32)       2080        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 41, 32)       128         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 41, 32)       0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 41, 32)       0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 34, 64)       16448       dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 34, 64)       256         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 34, 64)       0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 34, 64)       0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 27, 128)      65664       dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 27, 128)      512         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 27, 128)      0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 27, 128)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 27, 64)       8256        dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 27, 64)       256         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 27, 64)       0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 27, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 64)           0           dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 64)           0           dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128)          0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 64)           0           dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            65          activation_63[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 261,697\n",
      "Trainable params: 260,417\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =  52.340078830718994\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "glove = api.load(\"glove-twitter-25\") \n",
    "print(\"total = \",(time()-start))\n",
    "\n",
    "ptr_glove = PreTrainedEmbeddingsTransformer(glove,size=25)\n",
    "ptr_glove.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test['glove_encoded'] = ptr_glove.transform(df_test['text'].values)\n",
    "df_train['glove_encoded'] = ptr_glove.transform(df_train['text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "fasttext = api.load(\"fasttext-wiki-news-subwords-300\") \n",
    "print(\"total = \",(time()-start))\n",
    "\n",
    "ptr = PreTrainedEmbeddingsTransformer(fasttext,size=300)\n",
    "ptr.fit()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ptr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c175fc7620fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fasttext_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fasttext_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ptr' is not defined"
     ]
    }
   ],
   "source": [
    "df_train['fasttext_encoded'] = ptr.transform(df_train['text'].values)\n",
    "df_test['fasttext_encoded'] = ptr.transform(df_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext Transforms start at: 2019-06-12 15:50:49.517983\n",
      "Number of Unique Test Tokens for Fasttext transform 332242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1c9e2b295040cc9cbe9f30c3c1deba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxlen = 100\n",
    "batch_size = 4096\n",
    "embedding_dims = 300\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "X,y = ptr.transform(df_train['text'].values),df_train['PRICE'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_44: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-761b207a5622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'main_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-6a8fb0263422>\u001b[0m in \u001b[0;36mconv_layer\u001b[0;34m(inputs, n_kernels, kernel_size, dropout, dilation_rate, padding)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 dilation_rate=dilation_rate)(inputs)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_44: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(None,embedding_dims), dtype='int32', name='main_input')\n",
    "\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=5,padding='valid')\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=3,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = MaxPooling1D()(x)\n",
    "x = conv_layer(x,n_kernels=128,kernel_size=3,padding='valid')\n",
    "x = conv_layer(x,n_kernels=256,kernel_size=3,padding='valid')\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "\n",
    "\n",
    "xp = pre_dense_layer(x)\n",
    "x = Dense(128)(xp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "K.int_shape(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae','mse'])\n",
    "print(model.count_params())\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "- gl min max clipping\n",
    "- max(0,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
