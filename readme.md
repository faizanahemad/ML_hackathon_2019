# Process and Presentation
- Notebook 
Data Preparation
1D CNN concept
3 CNN models - word, char, pretrained
Baselining
Process of improvement
- Exploration
    - Target Distribution
    - Word Cloud hued by price
    - Inspecting Errors after predictions 
    - Q-Q plots of predicted prices with actuals
    
- Concepts
    - Manual LR schedules
    - Normalizing word vectors isn't a great idea.

# References
- [Keras Multiple GPU](https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras)
- [Using specific GPU](https://stackoverflow.com/questions/40069883/how-to-set-specific-gpu-in-tensorflow)
- [Reversing np_utils to_categorical of Keras](https://stackoverflow.com/questions/38845097/np-utils-to-categorical-reverse)
- [Saving a Keras Model](https://jovianlin.io/saving-loading-keras-models/)

# Data

