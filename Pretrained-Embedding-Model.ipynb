{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T10:56:06.982560Z",
     "start_time": "2019-06-12T10:56:06.943268Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np_utils\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, DepthwiseConv2D, Conv2D, SeparableConv2D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, concatenate\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Nadam, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from keras_contrib.callbacks import CyclicLR\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from data_science_utils.vision.keras import *\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import missingno as msno\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "from data_science_utils import dataframe as df_utils\n",
    "from data_science_utils import models as model_utils\n",
    "from data_science_utils import plots as plot_utils\n",
    "from data_science_utils.dataframe import column as column_utils\n",
    "from data_science_utils import misc as misc\n",
    "from data_science_utils import preprocessing as pp_utils\n",
    "from data_science_utils import nlp as nlp_utils\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from data_science_utils.dataframe import get_specific_cols\n",
    "\n",
    "import more_itertools\n",
    "from more_itertools import flatten\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib' from '/home/ec2-user/SageMaker/ML_hackathon_2019/lib.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "from importlib import reload\n",
    "import lib\n",
    "reload(lib)\n",
    "from lib import *\n",
    "\n",
    "from oclr import OneCycleLR, LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T09:42:02.848654Z",
     "start_time": "2019-06-12T09:41:52.143642Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"price_prediction/train.csv\")\n",
    "df_test = pd.read_csv(\"price_prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161f4a2bf3284fa2b01c42a68334bf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f404ecb6d204897a3c02e1aad9ef150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef23e6668e54434aaee2c8d95a443f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffe74b97df947419ecc3ea25813f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916fe79c821a4514a4f2bfdfb68d4440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bb6279a6de4e6aa5e4430f545fa980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['text'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_train['text']))\n",
    "df_train['text_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_train['text_encoded']))\n",
    "df_train['char_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_train['char_encoded']))\n",
    "\n",
    "df_test['text'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_test['text']))\n",
    "df_test['text_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_test['text_encoded']))\n",
    "df_test['char_encoded'] = Parallel(n_jobs=20, backend=\"loky\")(delayed(ast.literal_eval)(x) for x in tqdm(df_test['char_encoded']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GL encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Categorical fit start at: 2019-06-13 08:02:33.734957\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input to Neural Network: (61, 61), Output shape: (61, 69)\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 37 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      "37/37 [==============================] - 2s 57ms/step - loss: 0.2424 - val_loss: 0.2383\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 0s 53us/step - loss: 0.2370 - val_loss: 0.2334\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 0s 43us/step - loss: 0.2301 - val_loss: 0.2262\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.2196 - val_loss: 0.2160\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 0s 66us/step - loss: 0.2048 - val_loss: 0.2027\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.1854 - val_loss: 0.1862\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 0s 44us/step - loss: 0.1619 - val_loss: 0.1667\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.1354 - val_loss: 0.1449\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.1079 - val_loss: 0.1219\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.0820 - val_loss: 0.0992\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 0s 41us/step - loss: 0.0599 - val_loss: 0.0784\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.0431 - val_loss: 0.0610\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 0s 90us/step - loss: 0.0317 - val_loss: 0.0476\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 0s 49us/step - loss: 0.0248 - val_loss: 0.0379\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.0209 - val_loss: 0.0313\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.0188 - val_loss: 0.0270\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.0176 - val_loss: 0.0242\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 0s 270us/step - loss: 0.0170 - val_loss: 0.0224\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 0s 94us/step - loss: 0.0167 - val_loss: 0.0214\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 0s 77us/step - loss: 0.0167 - val_loss: 0.0208\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 0s 37us/step - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 0s 41us/step - loss: 0.0169 - val_loss: 0.0201\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 0s 49us/step - loss: 0.0169 - val_loss: 0.0200\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.0168 - val_loss: 0.0199\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.0168 - val_loss: 0.0199\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 0s 123us/step - loss: 0.0167 - val_loss: 0.0200\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 0s 90us/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 0s 38us/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 0s 42us/step - loss: 0.0169 - val_loss: 0.0200\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 0s 40us/step - loss: 0.0169 - val_loss: 0.0200\n",
      "Train on 24 samples, validate on 37 samples\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 0s 68us/step - loss: 0.0200 - val_loss: 0.0169\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 101us/step - loss: 0.0200 - val_loss: 0.0168\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 65us/step - loss: 0.0200 - val_loss: 0.0168\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 67us/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 79us/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 139us/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 150us/step - loss: 0.0198 - val_loss: 0.0169\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 57us/step - loss: 0.0198 - val_loss: 0.0169\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 57us/step - loss: 0.0198 - val_loss: 0.0169\n",
      "Neural Categorical fit done at: 2019-06-13 08:03:07.856665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<data_science_utils.preprocessing.NeuralCategoricalFeatureTransformer at 0x7f7b472a35f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_science_utils.preprocessing import NeuralCategoricalFeatureTransformer\n",
    "\n",
    "ct_nn = NeuralCategoricalFeatureTransformer(cols=[\"GL\"],prefix=\"gl_encoded_\",\n",
    "                                            target_columns=[\"PRICE\"],verbose=1,n_components=16,n_iter=200,)\n",
    "\n",
    "ct_nn.fit(df_train)\n",
    "\n",
    "ct_nn.skip_fit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ct_nn.transform(df_train)\n",
    "df_test = ct_nn.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_cols = get_specific_cols(df_train,prefix='gl_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =  91.9950692653656\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "glove = api.load(\"glove-twitter-25\") \n",
    "print(\"total = \",(time()-start))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr_glove = PreTrainedEmbeddingsTransformer(glove,size=25)\n",
    "ptr_glove.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext Transforms start at: 2019-06-13 08:57:47.014103\n",
      "Number of Unique Test Tokens for Fasttext transform 160522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11563b406ad7486797004392049c172a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=362403), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fasttext Transforms done at: 2019-06-13 08:57:56.228158\n",
      "Fasttext Transforms start at: 2019-06-13 08:57:56.476962\n",
      "Number of Unique Test Tokens for Fasttext transform 332242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb3acf9986a487a848ec626b9054b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1449608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fasttext Transforms done at: 2019-06-13 08:58:29.763856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test['glove_encoded'] = ptr_glove.transform(df_test['text'].values)\n",
    "df_train['glove_encoded'] = ptr_glove.transform(df_train['text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "glove = api.load(\"glove-twitter-50\") \n",
    "print(\"total = \",(time()-start))\n",
    "\n",
    "ptr_glove_50 = PreTrainedEmbeddingsTransformer(glove,size=50)\n",
    "ptr_glove_50.fit()\n",
    "\n",
    "df_test['glove_encoded-50'] = ptr_glove_50.transform(df_test['text'].values)\n",
    "df_train['glove_encoded-50'] = ptr_glove_50.transform(df_train['text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "fasttext = api.load(\"fasttext-wiki-news-subwords-300\") \n",
    "print(\"total = \",(time()-start))\n",
    "\n",
    "ptr = PreTrainedEmbeddingsTransformer(fasttext,size=300)\n",
    "ptr.fit()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fasttext_encoded'] = ptr.transform(df_train['text'].values)\n",
    "df_test['fasttext_encoded'] = ptr.transform(df_test['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "batch_size = 4096\n",
    "embedding_dims = 25\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "X,X_gl,y = df_train['glove_encoded'].values,df_train[gl_cols],df_train['PRICE'].values\n",
    "x_train, x_test,x_gl_train,x_gl_test, y_train, y_test = train_test_split(X,X_gl, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159686, 100, 25)\n",
      "(1159686, 100, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape((-1,100,25,1))\n",
    "x_test = x_test.reshape((-1,100,25,1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,)\n",
    "datagen.fit(x_train)\n",
    "train_iterator = datagen.flow((x_train,x_gl_train), y_train, batch_size=2048,shuffle=True)\n",
    "validation_iterator = datagen.flow((x_test,x_gl_test), y_test, batch_size=2048,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "main_input = Input(shape=(None,embedding_dims,1), dtype='float32', name='main_input')\n",
    "x = Lambda(lambda x:K.reshape(x,(-1,100,25)))(main_input)\n",
    "x = conv_layer(x,n_kernels=32,kernel_size=3,padding='valid')\n",
    "x1 = MaxPooling1D()(x)\n",
    "x2 = AveragePooling1D()(x)\n",
    "x = concatenate([x1,x2])\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "\n",
    "xp = x\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=3,padding='same')\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "\n",
    "xp2 = x\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=3,dilation_rate=2,padding='same')\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "x = concatenate([x,xp,xp2])\n",
    "x = transition_layer(x, n_kernels=64,dropout=0)\n",
    "x = pre_dense_layer(x)\n",
    "K.int_shape(x)\n",
    "auxiliary_input =  Input(shape=(len(gl_cols),), dtype='float32', name='aux_input')\n",
    "x_aux = Dense(4)(auxiliary_input)\n",
    "x = concatenate([x,x_aux])\n",
    "x = Dense(16)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x =Activation('relu')(x)\n",
    "\n",
    "main_output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])\n",
    "\n",
    "optimizer = Adam(lr=0.0001,)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mae','mse'])\n",
    "print(\"params = \",model.count_params())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model.hdf5\", monitor='mse', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = []\n",
    "\n",
    "# model.fit([x_train,x_gl_train], y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,callbacks=callbacks_list,\n",
    "#           validation_data=([x_test,x_gl_test], y_test))\n",
    "\n",
    "\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=len(train_iterator), \n",
    "                    validation_data = validation_iterator, \n",
    "                    validation_steps = len(validation_iterator),\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    callbacks=callbacks_list,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "params =  101633\n",
    "Epoch 1/5\n",
    "567/567 [==============================] - 364s 642ms/step - loss: 4031846918.7346 - mean_absolute_error: 1066.6701 - mean_squared_error: 4031846918.7346 - val_loss: 20270204.2412 - val_mean_absolute_error: 963.9843 - val_mean_squared_error: 20270204.2412\n",
    " - lr: 0.00001 \n",
    "Epoch 3/5\n",
    "567/567 [==============================] - 360s 635ms/step - loss: 4031529518.1321 - mean_absolute_error: 983.9032 - mean_squared_error: 4031529518.1321 - val_loss: 19970991.7471 - val_mean_absolute_error: 886.9307 - val_mean_squared_error: 19970991.7471\n",
    " - lr: 0.00001 \n",
    "Epoch 4/5\n",
    "567/567 [==============================] - 359s 633ms/step - loss: 4031241021.6406 - mean_absolute_error: 924.6773 - mean_squared_error: 4031241021.6406 - val_loss: 19779274.3431 - val_mean_absolute_error: 851.5251 - val_mean_squared_error: 19779274.3431\n",
    " - lr: 0.00001 \n",
    "Epoch 5/5\n",
    "567/567 [==============================] - 360s 635ms/step - loss: 4030976892.7566 - mean_absolute_error: 897.6240 - mean_squared_error: 4030976892.7566 - val_loss: 19615373.1328 - val_mean_absolute_error: 831.4093 - val_mean_squared_error: 19615373.1328\n",
    " - lr: 0.00001 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,)\n",
    "datagen.fit(x_train)\n",
    "train_iterator = datagen.flow((x_train,x_gl_train), y_train, batch_size=2048,shuffle=True)\n",
    "validation_iterator = datagen.flow((x_test,x_gl_test), y_test, batch_size=2048,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "main_input = Input(shape=(None,embedding_dims,1), dtype='float32', name='main_input')\n",
    "x = Lambda(lambda x:K.reshape(x,(-1,100,25)))(main_input)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=3,padding='valid')\n",
    "x1 = MaxPooling1D(pool_size=2)(x)\n",
    "x2 = AveragePooling1D(pool_size=2)(x)\n",
    "x = concatenate([x1,x2])\n",
    "xp = x\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=3,padding='same')\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "\n",
    "xp2 = x\n",
    "x = concatenate([x,xp])\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "x = conv_layer(x,n_kernels=64,kernel_size=3,dilation_rate=2,padding='same')\n",
    "x = transition_layer(x, n_kernels=32,dropout=0)\n",
    "\n",
    "x = concatenate([x,xp,xp2])\n",
    "\n",
    "x = transition_layer(x, n_kernels=128,dropout=0)\n",
    "x = pre_dense_layer(x)\n",
    "K.int_shape(x)\n",
    "auxiliary_input =  Input(shape=(len(gl_cols),), dtype='float32', name='aux_input')\n",
    "x_aux = Dense(4)(auxiliary_input)\n",
    "x = concatenate([x,x_aux])\n",
    "x = Dense(32)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x =Activation('relu')(x)\n",
    "\n",
    "main_output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])\n",
    "\n",
    "optimizer = Adam(lr=0.0001,)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mae','mse'])\n",
    "print(\"params = \",model.count_params())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model.hdf5\", monitor='mse', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = []\n",
    "\n",
    "# model.fit([x_train,x_gl_train], y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,callbacks=callbacks_list,\n",
    "#           validation_data=([x_test,x_gl_test], y_test))\n",
    "\n",
    "\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=len(train_iterator), \n",
    "                    validation_data = validation_iterator, \n",
    "                    validation_steps = len(validation_iterator),\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    callbacks=callbacks_list,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
